---
title: Redis学习笔记（二）
date: 2021-08-03 14:48:11
tags: Redis
categories: Redis
cover: http://image.hanelalo.cn/images/202111061317524.jpg
---

# Redis 学习笔记（二）

## Redis 数据结构

* String

* List

* Hash

* Set

* zset


底层数据结构：

* 简单动态字符串 Simple Dynamic String（SDS）
* 双向链表
* 压缩链表
* 哈希表
* 跳表
* 整数数组

### 问题

* 从 Redis 的指令上看，上面的底层数据结构，都是实现的值的数据结构，那键和值之间如何组织？

  不管是使用 Java 还是什么语言，存储键值对，想到的都是使用 Map 的数据结构，也就是哈希表。研究过 Java 中的 HashMap 就会知道，涉及到哈希表，必定要解决哈希冲突问题，以及扩容机制。

  当 hash 冲突过于频繁，会导致一个 hash 槽下对应的值的链表越来越长，影响查询效率，此时需要适时做 rehash 操作，其实就是扩容。

  Redis 内部维护了两张 hash 表，一开始插入数据，使用表 1，表 2 不分配空间，数据增多后，会触发 rehash：

  1. 给表 2 分配更大空间，比如表 1 的两倍。
  2. 将表 1 的数据拷贝到表 2。
  3. 释放表 1 的空间。

  重点在于第 2 步，因为数据量大，一次性拷贝完，会阻塞 Redis 线程。为了避免该问题，Redis 使用**渐进式 rehash。**

  渐进式 rehash 的实现原理是，Redis 每次处理请求的时候，就将表 1 中从索引位置 1 开始，顺便把该位置的值的链表移动到表 2，这样就能让 Redis 能一直处理请求，同时也完成了 rehash。

  ![](/img/post/progressive-rehash.webp)

* 为什么集合类型有好几种数据结构的实现，都很快吗？

  集合操作，首先需要在全局哈希表中通过键找到对应的集合，然后对集合进行增删改查。集合的操作效率，和集合的底层数据结构以及具体的操作有关系。

  集合类型的底层实现有 5 种：整数数组、双向链表、哈希表、压缩列表、跳表。整数数组和双向链表，都是顺序读写，操作效率较低，基本都是 O(N) 级别。

  **压缩列表**类似一个数组，不过在压缩列表的表头位置有三个字段：zlbytes、zltail、zllen。它们分别标识列表长度、列表偏移量、列中中 entry 个数，在表尾还有一个 zlend，表示列表结束。如果要查找压缩列表的第一个或最后一个 entry，根据表头的三个元素值，时间复杂度为 O(1)，其他元素的查找只能一个一个找，时间复杂度为 O(N)。

  **跳表**是在有序链表基础上增加了层层索引，通过索引跳转，快速定位。

  ![skip list](/img/post/skip-list.webp)

  以上图为例，普通链表要查询 100 这个元素，只能一个一个遍历 9 次，才能找到 100，如果是跳表，有一级索引，只需要查询 4 次，如果有二级索引，只需要查询 3 次。跳表的查询复杂度为 O(logN)。

* 简单动态字符串是什么？

  简单动态字符串，其实就是在实现 Redis 时，Redis 作者自己定义的一个字符串数据结构，里面包含了字符串的长度，因为有专门的属性表示字符串长度，所以在操作字符串的时候，不用在处理 C 语言字符串以 `\'0'` 结尾的情况。

## 为什么 Redis 单线程也能这么快？

* Redis 的操作基本都在内存中，并且选用的都是一些比较高效的数据结构，比如哈希表、跳表。

* 在网络 IO 上采用多路复用机制。

  Linux 中 IO 多路复用机制指的是一个线程处理多个 IO 流，允许内核中同时存在多个监听套接字和已连接套接字，内核会监听这些套接字上的连接请求或者数据请求，一旦有请求到达就交给 Redis 处理，从而实现了 Redis 一个线程处理多个 IO 的效果。

## AOF 日志

在 MySQL 中，有写前日志的概念，先记录变动日志，再写数据，方便故障恢复。但是 Redis 不一样，Redis 使用的是写后日志，也就是先执行命令，再记录日志。

### 为什么使用的是写后日志？

* redis 记录 AOF 的方式决定，以下面的 `set testkey testvalue` 为例， `*3` 表示这个命令有 3 个部分，`$3` 表示当前部分有 3 个字节，也就是 `set`。为了避免额外开销，记录 AOF 日志时并没有做语法检查，如果 AOF 是写前日志，那 AOF 中很可能就会存在执行错误的命名，所以先执行命令，再记录，能保证 AOF 文件中记录的肯定是正确的命令。

![](/img/post/redisc-cmd-to-aof.webp)

* 执行效率问题，先执行命令，再写入 AOF 日志，不会阻碍当前命令的写入操作。

### 存在的问题？

* 如果 Redis 执行完命令之后，还没来得及写入 AOF 日志就宕机了，怎么办？
* AOF 文件写入也是在主线程中执行，也就是通常情况下，必须等当前命令的 AOF 日志写完，才能执行下一条指令，如果写入 AOF 日志时，磁盘压力较大，那么后续的命令执行都会被阻塞。

这两个问题，都和 AOF 日志写入时机有关。

Redis 提供了三种写 AOF 的策略，通过 appendfsyc 配置：

* Always，同步写回，每条指令执行完之后，立马同步将日志写回磁盘。
* Everysec，每秒写回，每个命令执行完之后，只是先把日志写到 AOF 文件的缓冲区，每隔一秒把缓冲区内容刷新到磁盘。
* No，由操作系统控制写回磁盘时机，每次执行命令之后，只把日志写道 AOF 日志的缓冲区，具体的写回磁盘时间由操作系统决定。

这三种策略，从上到下，性能越来越好，但是相应的对丢数据的情况也越来越不友好。

Always 基本能做到不丢数据，但是因为是同步写回磁盘才算是执行完成，所以命令的执行效率比较低；Everysec 的执行效率有所提升，但是因为数据是每隔一秒写入一次磁盘，所以最多可能会丢 1 秒内的数据；No 是性能最好的，因为缓存写入磁盘的时机交给了操作系统，但同时，如果在缓存还没有刷到磁盘时就宕机了，那么丢失的数据可能就相当多了。

![](/img/post/aof-strategy-comparative.webp)

### AOF 文件越来越大，怎么办？

当 Redis 运行一段时间后，执行的命令越累越多，AOF 文件的体积也越来越大，逐渐的就会影响日志的写入性能。

针对这个问题，Redis 提供了 AOF 重写机制来解决。

举个例子，在 Redis 执行了以下指令后，AOF 文件中记录了两条命令。

```bash
set testkey testval1
set testkey testval2
```

在执行了 AOF 重写后的 AOF 文件中记录的命令翻译过来，就只有`set testkey testval2`，所以可以把 AOF 重写理解为将多条命令融合为一条命令。

### AOF 重写会阻塞吗？

不会。执行 AOF 重写的是后台子进程 bgrewriteaof。

每次执行重写时，都会从主进程 fork 一个 bgrewritwaof 子进程，主进程中最新的内存数据也会拷贝一份给 bgrewriteaof 子进程，然后 bgrewriteaof 子进程就可以在不阻塞主线程情况下，逐一把拷贝的数据写成 AOF 重写日志。

此时主进程依然在处理请求，依然会将日志写道原来的 AOF 日志文件的缓冲区，不同的是，此时因为后台子进程在进行重写操作，所以此时不仅要将日志写到原来的 AOF 日志缓冲区，还要写到 AOF 重写日志的缓冲区，等 bgrewriteaof 执行完成后，将重写日志缓冲区的内容也写入到新的 AOF 文件中，就完成了 AOF 重写操作。

![](/img/post/aof-rewrite.webp)

## RDB 内存快照

RDB 是 Redis 在某一个时刻的内存快照文件，使用 RDB 恢复数据的时候，因为 RDB 文件是内存快照，所以可以直接读进内存中，但是 AOF 因为记录的是指令，需要一条一条执行才可以。

所以从速度上来讲，RDB 肯定是比 AOF 要快很多的。

### 那么 RDB 是如何实现的？

Redis 提供了两个指令来进行 RDB 操作，分别是 save 和 bgsave。save 指令会在主进程中创建 RDB 文件，会阻塞主进程，bgsave 是一个专门用来写 RDB 文件的子进程，避免了生成 RDB 文件时阻塞主进程的情况。bgsave 也是 Redis 生成 RDB 文件的默认方式。

那么，bgsave 子进程在生成 RDB 文件的过程中，主进程中是否可以修改内存中的数据？

如果 bgsave 执行过程中不能对内存中的数据进行修改，那其实和 save 指令就没有多大差别了，所以 bgsave 执行过程中其实是可以修改内存中的数据的。

在执行 bgsave 时，采用操作系统的写时复制 (Copy On Write) 技术，主进程和子进程共享内存空间，如果主进程要修改内存中的某项数据，Redis 会提供这一块数据的副本，主进程在内存副本上修改，这样就不会影响到 RDB 数据的准确性。

![](/img/post/redis-bgsave.jpg)

简单来讲，bgsave 子进程是从主进程 fork 而来，和主进程共享了内存区域，RDB 文件记录的就是内存区域中的数据快照。如果在生成 RDB 文件过程中主进程要修改内存中的数据，为了不影响 RDB 文件的数据准确性，实际修改的是数据的副本。

### 什么时候做 RDB 合适？

RDB 和 AOF 不同，比较吃资源，每次 RDB 文件的写入都会有磁盘的 IO，如果频繁的进行 RDB 文件的生成，磁盘 IO 来的性能问题必能十分明显。但是如果两次 RDB 间隔时间过长，一旦服务器宕机，丢失的数据必定会变多，两次 RDB 间隔时间太短的话，就不得不考虑磁盘 IO 带来的性能问题。

在 Redis 4.0 开始，提出了一种 AOF 和 RDB 混用的解决方案。

### RDB 和 AOF 混用

举个例子就是，加入两次 RDB 的时间间隔为 t，在 T1 时刻进行了第一次 RDB，那么在 T1 到 T1+t 这段时间内的数据，将由 AOF 日志记录，这样就比单纯依靠 RDB 进行数据恢复带来的风险要低得多。

## 主从数据同步

在现代的分布式系统中，中间件一般的偶不会是单体部署，因为如果是单体部署，实例一旦挂了，可能会导致整个系统的瘫痪，所以在分布式环境下，Redis 也考虑到了高可用这一点，具体做法主要是一份数据多个副本，一个实例宕机了不要紧，另一个实例上还有全量的数据副本，Redis 依然可以继续提供服务。

Redis 的主从架构中，主从节点均可处理读操作，写操作均由主节点处理，然后讲数据同步给从节点。

![](/img/post/redis-master-slave.webp)

### Redis 主从节点的第一次数据同步

执行 `replicaof <ip> <port>` 就可以建立主从关系，然后数据同步会分为三个阶段：

1. 和主库建立连接，为全量复制做准备。

   从库向主库发送一个 psync 指令，表示要进行数据同步，指令参数包括主库的 runID 和复制进度 offset。第一次复制的时候，从库并不知道主库的 runID，所以改参数为 ? ，offset 此时设置为 -1，表示要进行全量复制。

   主库收到从库的 psync 指令后，会使用 FULLRESYNC 命令响应，同时也会带上主库 runID 和主库的写入偏移量 offset 两个参数，FULLRESYNC 表示这是一次全量复制。

2. 主库将所有数据同步给从库，从库收到后，本地完成数据加载。

   第一次全量复制以来的是 RDB 文件。因为同样的数据量，RDB 是内存数据直接存储的二进制文件，AOF 是指令集和，文件大小上，RDB 还是要小一点的，数据传输上肯 RDB 更快，而且从库收到后做数据加载的时候，直接将 RDB 文件读入内存肯定比执行 AOF 文件快很多。

   从库接收到主库发送的 RDB 文件后，会先清空本地的数据库，然后再加载 RDB 文件。在传输 RDB 文件过程中，主库依然会处理请求，这个时候如果发生数据改动， Redis 会将数据变动写入 replication buffer，专门用来记录主从同步期间发生的改动。

3. 将第二阶段收到的新命令同步给从库

   当 RDB 文件发送完成后，将 replication buffer 中的数据变动发送给从库，从库在执行一遍，就实现了数据同步。

### 从库太多，如何分担主库复制压力？

这里的问题在于，从库很多的情况下，如果都直接从主库进行全量复制，主库会频繁的 fork 子进程，这个过程是会阻塞主进程的，要是频繁发生，肯定会影响 Redsi 的性能，所以就有了“主-从-从”的模式，其实就是从库和从库建立主从关系。

![](/img/post/master-slave-slave.jpg)

 ### 主从断连了怎么办？

在主从进行第一次数据同步后，并没有断开网络连接，而是一直保持着连接，也就是**基于长连接的命令传播**，那如果主从断开连接后怎么处理？

在 Redis 2.8 之前，断开重连后，会直接进行一次全量复制，其实比较浪费资源。

Redis 2.8 开始使用的是增量复制，增量复制其实就是把断连期间的所有改动同步给从库。

### 如何实现增量复制？

增量复制主要通过 repl_backlog_buffer 实现，这是一个环形缓冲区，上面有两个偏移量，一个是主库的写入偏移量，一个是从库的同步偏移量，最开始的时候，两个偏移量在同一个位置，当主库不断处理请求，主库偏移量 master_repl_offset 逐渐变大，主从同步开始后，从库的同步偏移量 slave_repl_offset 也逐渐变大，正常情况下这两个偏移量应该是差不多的。

![](/img/post/repl_backlog_buffer.jpg)

当主从连接断开后，master_repl_offset 依然逐渐增大，但是 slave_repl_offset 不变了，master_repl_offset 和 slave_repl_offset 逐渐拉开距离，当重新建立连接后，只需要把 master_repl_offset 和 slave_repl_offset 之间的操作同步给从库即可。

以上便是 repl_backloh_buffer 的基本操作，但是，它是一个环形缓存，当断开连接足够长的时候，会出现 master_repl_offset 逐渐覆盖 slave_repl_offset，就像大学跑 5000 米的时候，体力好的同学会超圈一样，这样的话， repl_backlog_buffer 就不能支持重连之后的主从同步了。

针对上面这种 master_repl_offset 覆盖 slave_repl_offset 的情况，首先需要考虑给足空间，尽量避免这种“超圈”现象，此时可以通过 repl_backlog_size 这个参数来调节 repl_backlog_buffer 的大小，这个参数和所需缓冲空间大小有关：

```
缓冲空间大小 = 主库写入速度 * 操作大小 - 主从网络传输速度 * 操作大小
```

在实际的环境中，考虑一些突发情况，可以直接将 repl_backlog_size 设置为缓冲空间大小的 2 倍。

需要注意的是，不管怎样设置，极端情况下，还是可能会出现因为这种“超圈”现象引起的主从不一致，这个时候要是主从重新建立连接，会选择进行全量复制。

## 哨兵集群原理

在主从模式下，如果从库挂了，那客户端可以连接到主库或者其他的从库上进行读写，但是如果是主库挂了，因为写请求都是由主库进行处理，这个时候整个系统基本上也就基本停摆了。

当主库挂了之后，为了整个系统能正常运行，需要一种机制，保证集群中依然有正常的主从关系，比如尝试选一个从库做为新的主库，此时又会面临三个问题：

1. 主库真的挂了吗？
2. 选择那个从库作为新的主库？
3. 如何通知其他从库以及客户端，集群的主库发生了变更？

哨兵机制，就是为了解决主从故障切换的这三个问题。

从以上三个问题就可以知道，哨兵集群的作用就是监控、选主、通知。

所谓哨兵，其实就是一个运行在特殊模式下的 Redis 进程。

### 监控

监控，其实就是哨兵进程在运行时定时给所有主库和从库发送 `ping` 命令来检测实例是否还在运行中。如果从库没有在指定时间内响应，哨兵就判定改从库下线，如果主库在指定时间内没有响应，哨兵就判定该主库下线，然后开始进行**自动切换主库**操作。

这里的主要是判定 Redis 节点是否处于下线状态。

哨兵对于主库判定的下线状态有两种，**主观下线**和**客观下线**。

主观下线，就是哨兵在指定时间内没有收到主库对 ping 命令的响应，此时就可以判断为主观下线。如果是从库的话，直接标记为主观下线就可以真的下线了，因为从库的下线其实影响不大。

哨兵一般都是集群方式部署，所以当哨兵集群中有一定数量的哨兵都认为主库是主观下线时，可以判定为主库客观下线，当主库被判定为客观下线后，才会进行主从自动切换。

### 选主

选择新的主库，首先得保证新的主库的网络环境是可靠的，根据每个从库的历史网络环境统计进行筛选，Redis 哨兵有一项配置 down-after-milliseconds，表示主从断开连接最大超时时间，如果主库和从库在 down-after-milliseconds 内都没有连接上，就认为主从断开连接。如果发生断连次数超过 10 次，那说明网络环境实在不乐观，这样的从库肯定就直接筛选掉，不具备作为新主库的资质。

在筛选掉一部分从库之后，在剩下的从库中，哨兵按照从库优先级、复制进度、从库 ID 三个维度进行打分，最终谁得分最高，谁就是新的主库，这三个维度不是并列，而是有优先级关系，如果有通过优先级打分的过程中出现了一个从库的优先级最高，那它就是新的主库，不用再通过复制进度和 ID 进行打分。

#### 使用从库优先级选主

通过 slave-priority 设置从库优先级，比如其中一个从库的性能更好一点，就可以给这个从库的优先级设置高一点。

如果通过从库优先级没能选出新的主库，就会通过复制进度进行第二轮选主。

#### 通过复制进度选主

在前面讲过主从同步的时候有一个 repl_backlog_buffer 环形缓冲区，里面有 master_repl_offset 和 slave_repl_offset 两个偏移量，那么此时哪一个从库的 slave_repl_offset 更接近 master_repl_offset，谁就是新的主库。

如果通过复制进度依然没能选主新的主库，就进行第三轮选主。

#### 通过从库 id 选主

每个从库都有一个自己的 id，id 最小的从库，会被选为新的主库。

### 通知

哨兵将新的主库信息发送给客户端和从库即可。

### 哨兵集群的高可用

哨兵与哨兵之间建立连接，最开始是通过主库中的 `__sentinel__:hello` 频道发布自己的 ip 和端口，这样其他的哨兵只要订阅这个频道就能得知 ip 和端口，进而建立连接。

哨兵和从库建立连接，首先向主库发送 info 指令，主库返回从库的地址信息，哨兵就可以和从库建立连接。

#### 哪个哨兵节点执行主从切换？

* 投票表决主库是否客观下线

  哨兵节点判断主库主观下线后，向集群中其他的哨兵节点发送 is-master-down-by-addr 命令，其他哨兵节点给出回应。当获得足够的票数后，就将主库标记为客观下线，这里所需要的赞成票数通过哨兵配置文件中的 quorum 配置。如果有 5 个哨兵节点，quorum 配置为 3，表示需要有 3 个哨兵节点认为主观下线，主库才会标记为客观下线。

* 竞争主从切换操作权

  如果一个哨兵节点确定为执行主从切换的节点，那么它在竞争过程中必须满足两个条件：

  1. 获取半数哨兵的赞成票
  2. 票数大于 quorum 配置值

  如果一个集群只有 2 个哨兵节点，那么必须获得两个赞成票才能执行主从切换，这就导致如果有一个节点挂了，就无法进行主从切换，所以哨兵集群一般都有 3 个节点。

## 切片

### 为什么使用切片集群？

当单机数据量越来越大，每次进行 RDB 的时候，fork 子进程用的时间会越来越久，进而造成了主进程的阻塞，影响性能。

### 使用切片集群，需要解决什么问题？

* 怎么切片？

  Redis 3.0 之前没有官方解决方案，3.0 开始有个 Redis Cluster 解决方案，将整个集群中的数据分为了 16384 个哈希槽，Redis 每个键值对的 key 都会对应到这个 16384 个槽中的某一个。Redis Cluster 会默认均分这个 16384 个槽，比如集群有 N 个节点，那么每个节点上的哈希槽个数为 16384/N 个。

  除了默认均分之外，考虑到不同节点的配置不同，提供了 cluster addslots 命令手动分配，需要注意的是，必须将 16384 个哈希槽分配完，Redis 才能正常启动。 

* 客户端如何定位自己要访问的数据在哪里？

  集群中的节点之间在建立连接的时候，会将自己的哈希槽分布情况发送给对方，这样每个实例都能知道哈希槽的分布情况，当客户端连接到某个实例时，也能知道所有数据的分布情况。

  但是集群中的节点存在上、下线操作，并非一成不变。集群中有节点的增减时，需要重新分配哈希槽，为了负载均衡，Redis 会把所有数据都重新分布一遍。

  实例之间因为建立了连接，这些变化时刻可以知道，但是客户端要如何感知这些变化？

  Redis 提供了一种重定向机制，当客户端访问的数据不在本实例上时，返回一个 MOVED 响应信息，里面包含目标数据坐在的哈希槽以及所在的服务器地址。

  ```
  GET hello:key
  (error) MOVED 13320 172.16.19.5:6379
  ```

  客户端接收到 MOVED 指令后，重新发送请求到新的节点上即可。

  上面是客户端发送请求时数据同步已经完成的情况，但是更多的是数据还没有传输完成的时候，此时，会返回一个 ASK 错误码：

  ```
  GET hello:key
  (error) ASK 13320 172.16.19.5:6379
  ```

  客户端收到 ASK 错误后，向新的节点发送 ASKING 命令表示允许新节点处理接下来的请求。

  MOVED 和 ASK 重要的区别在于，MOVED 会更新客户端本地的槽和 Redis 实例对应关系的缓存，但是 ASK 不会，也就是说当收到一次 ASK 错误后，正常情况下后面还会有一次 MOVED，之后本地的缓存才会更新。

  
