---
title: 消息队列笔记
date: 2021-07-17 15:08:46
tags: 消息中间件
categories: 消息中间件
cover: http://image.hanelalo.cn/images/202111061320053.png
---

# 消息队列笔记

> 本文是学习极客时间《消息队列高手课》专栏的笔记，文中有绿色方块的图，也是取自该专栏。

## 为什么需要消息队列？

### 异步处理

以秒杀系统为例，一般需要风险控制、锁定库存、生成订单、短信通知、更新统计数据这 5 个步骤，仔细想想，其实只要风险控制和锁定库存这两步确定了，后面几步并不需要急着立马完成，这种场景下就可以在通过了风险控制并锁定了库存之后，发送消息到消息中间件，同时返回响应信息给用户，而剩下的 3 步就可以自行消费消息中间件中的消息，要是这 3 步的关系不大，甚至能直接并发进行这三步。

![](/img/post/second-kill.webp)

这样做的**好处**是：

* 可以更快的返回结果。
* 减少用户等待时间，实现了业务步骤上的并发，提高了系统性能。

### 流量控制

在高并发场景下，很多时候都会出现大量请求直接讲服务器打垮的情况，同样是秒杀系统，为了避免这种情况，在服务网关和后端服务之间加入消息队列，当有请求过来时，讲请求作为消息发送到消息队列，后端服务根据自身的情况进行消费。

![](/img/post/second-kill-2.webp)

这样做的**好处**是：

* 超时的请求可以直接丢弃，APP 直接做秒杀失败处理。
* 运维可以随时增加秒杀服务实例，不需要改动系统其他部分。

其实就是**流量削峰**了。

但是同样也是有**坏处**的：

* 系统层面增加了调用环节，响应时间必定变长。
* 上下游系统都变为异步调用，增加了系统复杂度。

上面的解决方案其实只是为了做到流量控制，如果能够预估到秒杀系统的处理能力，这时就可以实现一个令牌桶算法来控制请求的并发度以及最终秒杀成功的数量。

令牌桶算法：在消息中间件中设置一个匀速生成令牌的消息队列，每个请求到达之后，先从令牌队列中获取一个令牌，获取到了就可以继续往下走，获取不到就直接秒杀失败。

![](/img/post/token-bucket-algorithm.webp)

这种解决方案的前提是，能够**预估后端服务的请求处理能力，才能合理设置生成令牌的速度，不然有可能直接将后端服务打垮。**

### 服务解耦

在电商业务中比较常见的情况是，当一个订单创建时，可能会发生以下事件：

1. 支付系统发起支付流程
2. 风控审核订单合法性
3. 客服系统发送短信通知
4. 更新统计数据
5. 。。。。。。。

这个时候，订单服务的开发人员头大了，创建一个订单，为了对接下游的系统，还得专门为每个下游系统提供接口，不只是考虑订单创建的情况下，甚至什么场景还需要调用哪个下游系统也得在代码里体现出来，万一变了，还得立马改代码重新上线。

如果引入消息队列，订单服务只需要在生成了订单后发送一个事件到消息队列，下游系统谁关系这个事件，谁就自行消费，订单服务不管这些。

所以这个时候引入消息队列的**好处**是：

1. 上下游系统之间因为没有直接的接口调用，断开了 api 耦合，不会出现一个业务调用链上一个微服务的失败导致整个请求处理失败。下游系统如果挂了，因为消息还在，所以下游系统恢复之后可以继续消费消息。

> 一开始我一直没明白这里所谓解耦到底是怎么回事，带到我们公司正在做的微服务里面发现好像没什么用处。知道今天我才知道为什么，以为按照微服务的架构来讲，每个服务都需要数据自治，相当于订单服务在其他的服务中应该是有冗余一些必要的数据的，而我司现在做的微服务并没有做到这一点，所以也就不存在用 MQ 来解耦这个场景。



## 消息队列引入的问题

不管是什么技术，肯定不会是十分完美的，只可能是在特定场景下解决特定的问题，所以，引入消息队列，虽然有诸多有点，但是相应的也会带来一些问题。

### 延迟问题

因为在架构上，调用链上多出了一个甚至多个节点，有些场景下必然会导致处理的事件相应的会增加，比如前面讲到的令牌桶算法，每次请求都必须多一步获取令牌。

### 增加系统复杂度

每引入一种中间件，系统的复杂度和运维的门槛也必定会升高。

### 数据一致性问题

因为服务间的通信不再是 api 直接调用，所以并不能完全保证用户接收到响应的时候后端所有的消息消费逻辑都已经完成。幽默的说法是，订单创建了，但是又没完全创建好。

## 消息中间件选型

消息中间件选型，必要的 3 点是：

* 必须是开源产品

  大部分公司并没有完全自研的能力，只能选择开源，遇见问题也有开源社区和各种平台提供帮助，关键是实在逼不得已，可以改源码解决问题，而不是等作者发布下一个版本。

* 近年比较流行，社区有一定活跃度

  如果使用比较冷门的产品，遇见问题的时候，在网上寻求解决方案的成本会增高，甚至不一定能解决，也因此，对于社区的活跃度也有一定要求，而且流行的产品一般 bug 也比较少，遇见的基本也都有解决方案。

* 必须包含下面 3 个特性：

  1. 消息可靠性，确保不丢消息。
  2. Cluster，支持集群部署，确保不会因为一个节点宕机导致服务不可用或者丢失消息。
  3. 性能，其实都用到了消息队列了，肯定对性能有要求的，不然还用它干啥。

### 常见开源消息中间件

1. RabbitMQ

   **优点**：

   * 轻量级，易部署。它是所有消息队列中客户端支持的语言最多的一个，如果使用的语言比较冷门，可以考虑。
   * RabbitMQ 在生产者和队列之间还增加了一个 Exchange 模块，根据配置的路由规则将消息分发到不同的队列，比较灵活。

   **缺点**：

   * 开发的语言 erlang 冷门且学习成本高，和 Java 不可同日而语，如果遇见问题，又不懂 erlang，那就只能求助社区了。
   * 性能普通，根据硬件配置不同，每秒能处理几万到十几万条消息，对于性能要求很高的，建议不考虑 RabbitMQ。
   * 消息堆积不友好，设计理念上认为消息堆积本身就是一件不好的事，应当尽量避免，当消息堆积时，性能会急剧下降。

2. RocketMQ

   最开始由 Alibaba 开源，后捐赠给了 Apache 基金会。

   **优点**：

   * 使用 Java 语言开发，开源，方便做针对性的二次开发。
   * 对响应时延方面做了优化，大多数情况下能做到毫秒级响应，性能上比 RabbitMQ 高了一个数量级，每秒可以处理几十万条消息。
   * 近几年得益于 Alibaba 的影响力，社区十分活跃。

   **缺点**：

   * 因为是国产开源的软件，所以和周边生态的集成上可能相对于其他消息中间件略逊一筹，不过也一直在补足。

3. Kafka

   Kafka 最初的设计目的是为了处理日志，因为日志这种东西，就算偶尔丢失一两条影响不大，所以最开始的 Kafka 为了极致性能，牺牲了一些东西，在丢消息的处理上比较欠缺，甚至也不支持集群。**但是**后来 Kafka 慢慢的又将这些缺点补齐了。

   Kafka 使用 Java 和 Scala 语言开发，大量使用异步和批量的思想，所以它的性能是最好的，但是和 RocketMQ 也还在一个量级，但是，因为使用了批量的思想，如果单位时间内消息的数量不多时，时延反而会比较高，因为需要等生产者累计了某个数量的消息之后一起压缩再发送到 Broker 端。

   **优点**：

   * 高性能，比 RocketMQ 性能好，但依然在每秒几十万的量级。
   * 使用 Java 和 Scala 开发，方便二次开发和问题排查。
   * 社区活跃，这时活跃在国内外的开源产品，大数据和流计算领域基本都选它。

   **缺点**：

   * 要是生产者每秒的消息比较少，因为 Kafka 使用了批量处理的思想，可能反而会导致时延变长，所以 Kafka 不太适合在线业务场景。

总结一下：

> 如果说，消息队列并不是你将要构建系统的主角之一，你对消息队列功能和性能都没有很高的要求，只需要一个**开箱即用易于维护**的产品，我建议你使用 RabbitMQ。
>
> 如果你的系统使用消息队列主要场景是**处理在线业务**，比如在交易系统中用消息队列传递订单，那 RocketMQ 的**低延迟和金融级的稳定性**是你需要的。
>
> 如果你需要处理**海量的消息**，像收集日志、监控信息或是前端的埋点这类数据，或是你的应用场景大量使用了**大数据、流计算**相关的开源产品，那 Kafka 是最适合你的消息队列。

## 主题和队列

### 队列模型

早期的消息中间件的设计模型，就像“队列”这种数据结构一样，先入先出，由消息生产者入队，消息消费者出队，所以使用这种模型设计的消息中间件里面，**队列**指的就是用来装消息的“队列”数据结构。但是问题在于，按照“队列”数据结构的特性来设计，那么每条消息就只能被一个消费者消费，如果由多个消费者想消费同一条消息，此时，因为第一个消费者让消息出队了，后面的消费者就没消息可以消费。比如创建订单时，发送的“订单创建”的事件就是一条消息，加入这个时候风控服务和支付服务都要消费者条消息，但是因为是按照“队列”数据结构设计，就会导致只有其中一个服务消费成功。

![](/img/post/queue-model.webp)

所以，在“队列”数据结构的基础上，可以选择为每个消费者建立一个队列，没次发送消息，其实就是每个“队列”都进行一次入队操作。这种做法，本质上就是在消息中间件中将消息复制很多个副本，而且，消息生产者还必须知道有哪些消费者，因为这样才知道要发送到哪些队列中。讲到这里终于发现这个设计的坏处：

* 本质上是消息复制很多次，浪费资源。
* 生产者必须知道有哪些消费者，从系统架构层面看，和最开始讲到的消息中间件的“服务解耦”设计理念相悖。

### 发布-订阅模型

前面讲了原始的队列模型，发现对于多个消费者的场景，解决方案不人性化。所以，发布-订阅模型支持了一条消息被多个消费者消费的场景。

![](/img/post/publish-subscribe-model.webp)

其中，消息发送方被称为**发布者**，消息消费者被称为**订阅者**，消息中间件服务端存储消息的容器称为**主题**。发布者将消息发布到指定的主题中，订阅者如果想要消费某条消息，必须订阅这个消息所在的主题，订阅者可以接收到订阅的主题中的所有消息。

当只有一个消费者时，其实就是一个队列模型。所以两者的主要区别在，一条消息能不能被多次消费。

### RabbitMQ 如何解决多消费者问题？

RabbitMQ 目前使用的消息消息模型，依然是队列模型，那么它如何解决多消费者问题？

在前面的消息中间件的选型小节中，讲到 RabbitMQ 在架构上多了一个 Exchange 模块，用来做消息的路由，一条消息到底要发送到哪些队列，需要对 Exchange 做配置。

![](/img/post/rabbitmq-exchange-arch.webp)

看上面的图，发现生产者并不是直接将消息发送到队列，而是发送到 Exchange 模块，由 Exchange 模块自己再做分发，决定消息都要发送到哪些队列。这里的设计，就像重构的时候，比较流行的一句话叫做“没有什么是封一层不能解决的”，这里我认为 Exchange 就是封的那一层，从而实现了“服务解耦”。

### RocketMQ 除了发布-订阅模型，为什么还有队列？

RocketMQ 使用的是发布-订阅模型，并且术语表中的发布者、订阅者、主题者三个概念也符合前面的解释。

但是，RocketMQ 中依然有队列这样一个重要的概念，那么为什么需要队列呢？

首先得知道，不管是发送消息还是消费消息，都会设计到和服务端得网络通信，同时也就会带来消息发送失败、消息消费失败等问题，RocketMQ 为了解决这些问题，实现了**请求-确认**模式，发送消息时，当服务端接收到消息后会通知发布者，如果发布者迟迟未收到通知，会尝试重新发送，消息消费时，消费者消费了消息，会给消息中间件的服务端一个反馈，表示某条消息已经消费完成了，如果服务端迟迟没有收到确认的通知，会尝试将消息重新推送。

队列要解决的问题时消费端消费时间过长、消费失败重试的场景。

在普通的发布-订阅模型下，如果消费者消费失败了，需要重试的话，主题只有一个，其他所有订阅了这个主题的消费者就必须等这个消费者将这条消息消费过后，才能继续消费，这样对并发的消费并不友好，很多场景也不需要这种等待。

对于上述问题的解决方案就是，每个主题下维护多个队列，生产者发送消息时就已经确定了消息所在的消息队列，每个队列持有的 topic 的部分消息，各自队列中的消费进度可以不一样。集群消费模式下，每个队列上的消费进度存储在 Broker 端，同一个消费者组中，每个队列只能有一个消费者实例进行消费，所以队列记录的消费进度，本质上是消费者组在这个队列上的消费进度，这样就做到了集群消费模式下，每条消息在组内只消费一次。

![](/img/post/rocketmq-consum-pattern.webp)

在 RocketMQ 中，每个订阅者，可能对应的不只是一个消费者，而是由多个**消费者**组成的一个**消费者组**，相应的发布者其实对应的也是一个**生产者组**。

然后就是，前面讲到，RocketMQ 的队列是主题的全量消息，那岂不是和队列模型一样造成了资源浪费？

其实不是的，RocketMQ 的消息存储设计上，所有消息都顺序存储在 commitlog 中，队列只是记录了消息 id 和消息在 commitlog 中的位置偏移量而已，所以也没造成资源浪费，只能说是使用空间换时间。

### Kafka 的消息模型

Kafka 和 RocketMQ 的模型设计其实是差不多的，只不过 RocketMQ 中的队列，在 Kafka 中叫做**分区**(partition)。需要注意的是，这里只是**消息模型上两者是一致的，但是具体实现上，肯定是不一样的**。

## 基于 MQ 的分布式事务的实现

### 事务特性

* 原子性

  一个事务操作不可分割，要么一起成功，要么一起失败。

* 一致性

  在事务执行完成前，独到的一定是更新前的数据，执行完成后，读到的一定是更新后的数据，不存在一个时刻可以读到更新过程中的数据。

* 隔离性

  事务之间不互相干扰。

* 持久性

  事务一旦提交，后续发生的其他操作都不会对这次事务的结果产生影响。

这四个特性，如果分布式事务都要严格实现，几乎不可能，甚至单独要实现严格的数据一致性就会花费巨大的成本，最后只能退一步选择最终一致性。

在实际应用中的分布式事务实现由 2PC 、TCC 和事务消息，各自都存在问题，不是完美的解决方案，需要根据具体场景做出选择。

**事务消息**适合需要异步更新数据，对数据实时性要求不太高的场景。

### MQ 如何实现事务消息？

现在的电商网站都有购物车和订单的概念，购物车中的商品下单后，购物车中对应的商品会被清理掉。

订单和购物车是分开的两个系统，必定没办法在同一个本地事务中更新各自的数据，势必会出现下单成功，清理购物车失败，或者请求购物车成功，但是下单失败的场景。

此时就可以考虑使用 MQ 实现分布式事务来解决这个问题。

![](/img/post/transactional-message.webp)

1. 订单系统首先在消息中间件上开启一个事务。
2. 然后发送一个**半消息**。
3. 执行本地事务，创建订单。
4. 提交或回滚消息队列中的事务。
5. 如果事务要提交，消息中间件将消息投递到购物车系统。

**半消息**，本身是一条完成得消息，只不过在事务提交之前，对消费者不可见、不能被消费。

这里有一个问题，如果第四步失败了怎么办？

对于这种情况，Kafka 会直接抛异常，交由用户处理。RocketMQ 则是给出了另一种解决方案。

### RocketMQ 中分布式事务的实现

RocketMQ 的分布式事务实现流程中，增加了事务消息反查的机制来解决事务消息生产者提交失败的问题。

如果 Producer 在第 4 步失败，RocketMQ 的 Broker 因为迟迟没有收到提交或者回滚事务的通知，就会定期去 Producer 上查询这个事务对应的本地事务状态，根据反查的结果决定事务消息提交还是回滚，这个反查本地事务的实现，不依赖消息发送放的特定节点，不然万一 Producer 在执行第 4 步时挂了，那反查也会失败。

![](/img/post/rocket-half-message.webp)

上面的流程图解释了 RocketMQ 的分布式事务实现：

1. 生产者发送半消息到 Broker。
2. Broker 返回确认收到半消息。
3. Producer 执行本地的事务。
4. Producer 根据本地事务执行结果，通知 Broker 提交或回滚事务，Broker 接收到通知后，如果事务要提交，就投递消息，如果事务回滚，就删除半消息。
5. 如果 Broker 一直没收到提交或回滚事务的通知，就向 Producer 反查事务。
6. Producer 接收到反查事务的请求，查询本地事务的执行状态并返回。
7. Broker 根据反查结果决定事务回滚或提交。

需要注意的是，反查的时候，处理反查请求的生产者实例和最开始发送半消息的生产者实例可以不是一个，意思是，反查逻辑不应该依赖生产者实例本身。比如前面创建订单的逻辑，反查逻辑可以是直接根绝订单号查询数据库中是否有这个订单，如果有，就证明本地事务执行成功。

这里有两个疑问：

**1. 如果生产者的本地事务成功了，事务消息也提交了，但是消费者消费失败了，如果不是消费者本身的问题，而是消息的业务数据本身就有问题，此时要怎么处理？**

这种情况，肯定无法再回滚生产者端的数据，而且消息中间件本来就是为了解耦，所以也不应该影响生产者端的数据。而对于消费者，多次消费失败的消息，会将这种消息放到一个特殊队列中，等待人工处理，正常情况下，这种情况一般是偶发的。

**2. 为什么不等本地事务执行完之后直接发送一条普通消息给消费者消费，而一定要事先发送半消息？**

执行本地事务成功后，如果发送消息失败了，消费者端不会有消息可以消费。

> RocketMQ 事务消息示例：https://github.com/hanelalo/example/tree/main/rocketmq-example

## 如何做到不丢消息？

### 如何排查丢消息问题？

生产者发送消息时，给消息附加一个消息有序的序号，在消费者统计序号，缺少的序号就是丢失的消息。

为了避免对业务代码的侵入，生产者给消息附加序号、消费者统计序号这两步都应该是放在客户端的拦截器中实现。

### 生产阶段丢消息

消息生产阶段丢消息，就是消息发送失败，此时需要在生产者端对发送结果进行检查和异常处理，就能保证不丢消息。

### 存储阶段丢消息

消息最终都会存储在 Broker 上，如果 Broker 首先新消息后还没来得及落盘，Broker 就宕机，此时就会出现丢消息的情况。不同的部署模式，有不同的解决方案。

* 如果 Broker 是单机部署，只能设置为消息真正落盘后再返回确认信息给生产者，在 RocketMQ 中，直接将 flushDiskType 设置为 SYNC_FLUSH 即可。
* 如果是集群部署，需要配置成至少需要消息成功发送到了两个 Broker，才返回确认信息给生产者，如果其中一台 Broker 宕机了，还有其他 Broker 可以存储消息。

### 消费阶段丢消息

消费者会先从 Broker 拉取消息，此时丢消息的情况一般都是因为先发送了消费确认的消息，再进行消费端的业务处理，如果消费端业务处理失败了，消息就丢了，因为对 Broker 来讲，这条消息已经消费成功了。

所以，在消费端必须先进行业务处理，再发送消费确认的信息到 Broker。

## 如何解决重复消息问题？

### 什么是消息传递服务质量标准

* At most once

  消息传递最多成功一次，最不可靠的质量，允许丢消息。适用于消息可靠性要求不高的场景，比如日志收集，偶尔丢一行日志影响也不大。

* At least once

  至少传递成功一次，消息传递时至少成功一次，允许消息重复。

* Exactly once

  消息恰好传递成功一次，不允许丢消息，也不允许重复。

主流的消息队列中间件服务质量都是 At least once 级别。

### 幂等解决重复消息

在消费端，让消息的消费逻辑具有幂等性。

**幂等**：任意操作，执行一次和多次的影响是一样的。

可以认为 At least once + 幂等 = Exactlly once。

#### 使用数据库唯一约束实现幂等

适用于消息消费时插入的数据有不可重复的字段的场景。

#### 为更新数据设置前置条件

适用于更新数据的场景。

* 可以在更新前确认目标数据是否正确，比如确认字段 amount 的值是 500 时，才会执行更新语句，将 amount 更新成原来的值加 100。
* 为数据加上版本号，没更新一次，版本号加 1，每次更新，都需要确认更新前的版本号是否正确。

#### 使用全局唯一标识

为消息生成全局唯一的标识，消费者端没消费一条消息，就比较这个 id 的消息为已消费。

方案思路简单，但是实现十分困难，分布式唯一性 id 本身就是难点，设置消费状态还需要使用分布式事务，而分布式事务的实现本身就是一个问题。

### 思考

**为什么大部分消息队列都选择只提供 At least once 的服务质量，而不是级别更高的 Exactly once 呢？**

1. 严格实现 Exactly Once，势必会导致 Broker 处理新消息得性能下降。
2. 就算 Broker 做到了 Exactly once，消费者如果消费成功，但是 ack 失败，依然会造成对同一条消息重复消费，Broker 做的 Exactly once 完全没有意义。

## 消息积压如何处理？

因为一般情况下，业务节点对请求得处理逻辑比消息队列对消息得处理逻辑要复杂得多，所以消息挤压其实是无法完全避免得问题，只能通过优化，让消息生产者和消费者更好的配合消息队列，达到最佳性能。

### 生产端优化

其实生产者端的优化和队列中的消息挤压关系不大。

如果消息发送太慢，那可能是发送消息前的业务处理太耗时，因为发送消息一般都是放在最后一步。

然后，对于不同业务场景，也需要选择不同的消息发送的模式。

如果是在线业务场景，业务上更在意时延，那就选择并发的方式发送消息；如果是离线的分析场景，不关心时延，更关心吞吐量，那就选择批量发送，使用少量的并发就可以提高吞吐量。

### 消费端优化

如果消费的速度跟不上消息生产的速度，此时就会出现消息积压。

如果消费端的性能问题只是暂时的，那么消费端的性能恢复后，积压的消息自然也会随着消费慢慢解决。

如果消费端的性能一致比生产端慢，那就会导致消息不断积压，最后队列被填满，造成消息丢失，这是一个严重的故障。

所以，**一定要保证消费端性能比生产端性能高，才能更好避免消息积压。**

除了优化消费端代码性能，还可以选择消费者的横向扩展，增加消费者实例数，需要注意的时候，**扩展消费者的同时，需要同步增加订阅的主题中的队列数量，确保消费者数量和队列数量一致**，因为每个队列每个时刻只能一个线程消费。

### 总结

突然的消息积压，要么是消息发送变快了，要么是消息消费变慢了。

如果是因为网站搞活动这种活动导致消息发送变快，那就只能增加消费者是实例数，如果没资源可以分配了，那就只能忍痛关闭一些不重要的业务系统，释放资源。

消费变慢的情况，可能是消费者运行时发生了死锁或者卡在了资源竞争上。

还有一种场景，消费速度和生产速度没明显变化，此时需要排查是否是因为某条消息消费失败，导致一直在重复消费这条消息。
