---
title: Redis学习笔记（一）
date: 2020-10-24 17:37:02
tags: Redis
categories: Redis
cover: https://hanelalo.github.io/images/202111061352634.png
---

# Redis 学习笔记（一）

## 持久化

Redis 提供了两种持久化策略，AOF 和 RDB，AOF 是直接保存服务器保存的指令，服务器启动时再重新执行这些指令即可，而 RDB 则是保存一份内存的二进制快照，Redis 启动时加载，如果服务器开启了 AOF 功能，会优先加载 AOF 的文件，如果没开启 AOF 功能，才会加载 RDB 文件。

### AOF 持久化

AOF 持久化是以命令请求的方式保存，AOF 分为命令追加、文件写入、文件同步三个步骤。

1. 命令追加。AOF 配置打开时，每执行完一个写命令之后，这次命令执行会以协议格式写到 aof_buf 缓冲区。

2. 文件写入与同步。Redis 的进程从实现上是一个事件循环，这个循环中文件事件负责接收客户端命令请求和回复命令，时间事件执行一些定时任务，比如定期删除过期键。每次文件事件可能会处理一些写命令请求，就可能会有新的内容写入到 aof_buf 中，所以每个事件循环之后，都会考虑是否要将 aof_buf 中的内容写入到磁盘文件中。而在将 aof_buf 中的内容持久化时，根据`appendfsync`配置又会有不同的行为，在讲解`appendfsync`配置之前，先了解一下文件同步，现代操作系统在写入文件时，其实并不是调用写方法就真的写到文件里去，为了提高性能，采取按页存储的策略，当要写入的数据达到一定的大小时才真正的写到磁盘文件中，在此之前其实是将数据保存在缓存中，这个缓存叫做 PageCache，前面讲的文件写入，其实是将文件内容从 aof_buf 写入到了 PageCache，而同步的意思就是从 PageCache 将文件内容写入到真正的文件磁盘中。接下来看看`appendfsync`这项配置的说明及其特性：

   * always

     将 aof_buf 中所有内容写入 PageCache 并同步到 AOF 文件中。因此 always 是三种配置种效率最低的一个，但是也因为是实时写入和同步的，安全性也是最高的。

   * everysec

     将 aof_buf 中的内容写入 AOF 文件的 PageCache 中，如果当前距离上次同步文件超过 1 秒，则同步文件，这个动作由单独的线程完成。因为并不是每个事件循环都会同步，所以效率上比 always 快，就算故障停机，也只会丢失 1 秒的数据而已，安全性也还在可接受的范围内。

   * no

     仅仅只是将 aof_buf 中的内容写入到 PageCache 中，不主动同步，何时同步交由操作系统决定。因为该模式下无需执行同步操作，所以效率是最快的，但是因为同步依赖于操作系统的判断，所以该模式的同步时间也是三种模式种最长的，并且安全性也不如前两种，如果不小心故障停机，会丢失上次同步之后的所有数据。

#### AOF 重写

因为 AOF 是以命令请求的方式存储，当 AOF 中的文件的内容越来越多时，文件越来越大，可能会造成一些意想不到的问题，为避免一些不必要的文件膨胀，Redis 提供了文件重写的功能。这个功能具体有什么作用呢？

举个例子，假如 redis 连续执行以下命令：

```bash
redis> RPUSH list "A" "B"
redis> RPUSH list "C"
redis> RPUSH list "D"
```

三条命令都是向 list 里面加入一个元素，按照前面对 AOF 的理解，会保存三条命令请求的记录到 AOF 文件中，但是仔细想想，其实只需要保存一条命令请求就行了，一条命令将上面三条命令的内容全都写入，其实这就是重写的原理了。

执行 AOF 重写的指令是`BGREWRITEAOF`。

AOF 重写的时候并不是读取已经存在的 AOF 文件再进行重写，而是直接将当前内存中各个键值对最新的值以命令请求的方式保存。

这里还会涉及到一个问题，就是缓冲区溢出的问题，如果一个键值对的内容很多的时候，比如哈希表、列表等，不加限制的话，可能会造成客户端的缓冲区溢出，所以 Redis 设定了保存的每条指令的大小，当一条指令的内容超过这个阈值时，就会使用新的指令记录剩下的内容。

当执行 AOF 重写时，会阻塞当前的线程，所以 Redis 将这个指令的执行放到了子进程里面，当子进程执行重写的时候，如果服务器的服务进程又处理了写命令的请求，就会导致子进程重写完之后的结果和现在的内存实际的数据不一致。

为了解决上面的问题，Redis 又提供了一个重写的缓冲区，在创建子进程执行重写开始，服务器接受的写命令，不仅会写入到 AOF 缓冲区，还会写入到 AOF 重写缓冲区，当子进程执行完之后，会通知父进程将 AOF 重写缓冲区的内容写入并同步到 AOF 重写的文件中，然后再将重写的文件改名，覆盖之前的 AOF 文件，整个过程中，父进程只在将重写缓冲区的内容写入和同步到文件以及改名时会阻塞，其他时候都可以正常处理请求。

经过上面的讲解，其实 AOF 重写后的文件肯定是比普通的 AOF 持久化文件要小很多的，毕竟对指令进行了“压缩”。

### RDB 持久化

RDB 持久化策略，是将当前内存中的键值对以二进制的形式保存到磁盘，Redis 启动时会自动加载 RDB 文件。

要通过 RDB 的方式持久化，执行的命令是 `SAVE` 或者 `BGSAVE`，这两者的区别在于，`SAVE`会阻塞服务器进程，指令执行过程中，服务器不能处理任何指令请求，而`BGSAVE`则是派生一个子进程来持久化，父进程继续处理指令请求。

因为 BGSAVE 是交由子进程执行，不会阻塞父进程处理命令请求，所以 redis 提供了`save` 配置项，用来配置自动执行`BGSAVE`。

以官方提供的配置为例。

```
save 900 1
save 300 10
save 60 10000
```

这三行配置的意思分别是：

* 900 秒内至少进行了 1 次修改，则执行`BGSAVE`
* 300 秒内至少进行了 10 次修改，则执行`BGSAVE`
* 60 秒内至少执行了 1000 次修改，则执行`BGSAVE`

## Redis 过期键删除策略

解决方案分为三种：

* 定时删除

  为每个设置过期时间的键建立一个定时器，到时间就删除该键。如果为每个有时效的键都建立一个定时器，那么当过期键数量到达一定量级时，就算内存充裕，就会造成 CPU 资源的紧张。

* 惰性删除

  当键过期时先不管，访问键时，再判断当前键是否过期，过期就执行删除逻辑，没过期就返回值，这种策略对 CPU 来说很友好，但是如果一个过期键长期不被访问，就会长期存在于内存中，当这样的键较多时，就会造成内存的浪费。

* 定期删除

  设定一个时间周期，每隔一个时间周期对数据库检查一次，删除里面的过期键。从定时删除和惰性删除的介绍来看，都并不是很完美，总会顾此失彼，定时删除对 CPU 不友好，惰性删除可能对内存不是很友好，定时删除则更像是两者折中的策略，既不会造成很大的内存浪费，也不用建立很多定时器对 CPU 造成很大压力。

Redis 采用的是**惰性删除+定期删除**的组合策略。

### RDB 和 AOF 对过期键的处理

在之前讲过 RDB 和 AOF 两种持久化方案，那么这两种持久化方案针对过期键会怎么处理呢。主要关注以下三个问题：

1. **RDB 和 AOF 在持久化时，如何处理过期键？**

   RDB 在持久化时，会对过期键检查，过期的键不会持久化到二进制文件中。

   AOF 持久化时，并不会查看键是否过期，但是因为 AOF 会记录每个写指令，所以当键过期后，惰性删除或者定时删除时，肯定会有一个删除过期键的指令，这个指令也会被显式记录到 AOF 文件中。

2. **RDB 和 AOF 在加载时，如何处理过期键？**

   当 RDB 文件加载时，如果  redis 运行在复制模式下，那么主服务器不会加载已经过期的键，从服务则全部都会加载，但是主从同步的时候，因为主服务器上已经没有了过期键，所以从服务器上过期的键也会被同步掉。

3. **AOF 重写时，如何处理过期键？**

   AOF 重写和 RDB 持久化一样，会忽略掉过期键。

### 主从复制对过期键的处理

主服务器接收到读请求时，会检查键是否过期，过期则删除键，并向从服务器发送删除指令，使从服务器上的过期键也被删除。

但是如果读指令发送到了从服务器，从服务器并不会检查键是否过期，而是直接返回键的值，直到接收到主服务器发来的删除该过期键的指令之后，从服务器上的过期键才会被删除。

## 主从复制

redis 主从复制有两个版本，一个是 redis 2.8 以前的版本，一个是从 redis 2.8 开始的版本。

不管是新的还是旧的版本，对于主从复制大方向上考虑两种情况：

* 从服务器第一次和主服务器同步数据
* 从服务器和主服务器断开连接一段时间后，重新连接时同步数据

不管哪种情况，都是为了保证主从服务器上的数据一致性，所以当主服务器执行了写命令时，会发生命令传播，就是主服务器会向所有从服务器发送刚刚执行的写指令，保证数据一致性。

**那么 redis 2.8 以前的版本和新版本的区别在哪里？**

*先看看 redis 2.8 以前的版本：*

当从服务器第一次向主服务器同步数据。

1. 向主服务器发送一条 `SYNC` 指令。
2. 主服务器收到 `SYNC` 指令后，执行 `BGSAVE` 生成 RDB 文件，同时生成一个缓冲区记录从执行 `BGSAVE` 开始执行的所有写命令。
3. 主服务器生成 RDB 后，将 RDB 文件发送给从服务器。
4. 从服务器载入接收到了 RDB 文件到内存。
5. 主服务器将刚生成的缓冲区中的指令发送给从服务器，从服务器执行后，和主服务器的数据达成一致。

执行完以上步骤，当主服务器再接受到写指令时，会向从服务器也发送一次相同的指令，保证数据一致。

如果从服务器和主服务器意外断开连接，再重新连接时，会再次执行上面所有步骤，虽然最终达到了数据一致，但是其实没必要这样做，因为如果断开连接之前的数据，从服务器有持久化，那重新连接时其实只需要同步在断开连接期间主服务器进行的修改即可。

所以旧版复制实现，在重连时，效率不够。

*在 redis 2.8 开始，实现了新的复制方式。*

redis 2.8 版本开始的复制实现，依靠 `PSYNC` 命令。

`PSYNC` 有两种模式，一种时完整重同步，是针对从服务器第一次同步数据的实现，一种是部分重同步，针对从服务器断开重连的实现。

针对第一次同步数据的情况，也就是完整重同步，和 `SYNC` 一样的处理。

如果是断开重连的情况，触发的就是部分重同步，这里涉及到一个复制偏移量的概念，主服务器会记录当前已经被从服务器同步的偏移量，从服务器也会记录自己的同步偏移量，断开重连后，当主从偏移量不一致时，就复制偏差的这部分数据就好了。

举个例子，最开始主服务器 M 复制偏移量为 10000，从服务器 A、B、C 的偏移量也是 10000，此时主从数据一致，然后从服务器 A 和主服务器断开连接，此后，主服务器执行了写指令，发生指令传播，B、C 从服务器复制成功，M、B、C 三台服务器的偏移量变为 10033，然后  A 服务器恢复连接，此时和主服务器有 33 个偏移量的数据未复制，向从服务器发送 `PSYNC` 指令，并报告当前偏移量时 10000，最终主从服务器就会同步中间这 33 个偏移量的数据。

### 基于 Docker 搭建一个主从架构

#### 主服务器配置

主要修改以下几项配置：

```
requirepass <password> # 设置主服务器 redis 密码
# bind 127.0.0.1 
pretected-mode no
```

#### 从服务器配置

从服务器修改配置项如下：

```
requirepass <password> # 从服务器 redis 密码
slaveof <master_ip> <master_port>
masterauth <master_password>
```

